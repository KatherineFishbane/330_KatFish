/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
/******/ (() => { // webpackBootstrap
/******/ 	"use strict";
/******/ 	var __webpack_modules__ = ({

/***/ "./src/audio.js":
/*!**********************!*\
  !*** ./src/audio.js ***!
  \**********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   analyserNode: () => (/* binding */ analyserNode),\n/* harmony export */   audioCtx: () => (/* binding */ audioCtx),\n/* harmony export */   bassBoost: () => (/* binding */ bassBoost),\n/* harmony export */   loadSoundFile: () => (/* binding */ loadSoundFile),\n/* harmony export */   pauseCurrentSound: () => (/* binding */ pauseCurrentSound),\n/* harmony export */   playCurrentSound: () => (/* binding */ playCurrentSound),\n/* harmony export */   setVolume: () => (/* binding */ setVolume),\n/* harmony export */   setupWebaudio: () => (/* binding */ setupWebaudio),\n/* harmony export */   trebleBoost: () => (/* binding */ trebleBoost)\n/* harmony export */ });\n// 1 - our WebAudio context, **we will export and make this public at the bottom of the file**\r\nlet audioCtx;\r\n\r\n// **These are \"private\" properties - these will NOT be visible outside of this module (i.e. file)**\r\n// 2 - WebAudio nodes that are part of our WebAudio audio routing graph\r\nlet element, sourceNode, analyserNode, gainNode;\r\nlet highShelfFilter, lowShelfFilter;\r\n\r\n\r\n// 3 - here we are faking an enumeration\r\nconst DEFAULTS = Object.freeze({\r\n    gain: 0.5,\r\n    numSamples: 256,\r\n});\r\n// 4 - create a new array of 8-bit integers (0-255)\r\n// this is a typed array to hold the audio frequency data\r\nlet audioData = new Uint8Array(DEFAULTS.numSamples / 2);\r\n\r\n// **Next are \"public\" methods - we are going to export all of these at the bottom of this file**\r\nconst setupWebaudio = (filePath) =>{\r\n    \r\n    // 1 - The || is because WebAudio has not been standardized across browsers yet\r\n    const AudioContext = window.AudioContext || window.webkitAudioContext;\r\n    audioCtx = new AudioContext();\r\n\r\n    // 2 - this creates an <audio> element\r\n    element = new Audio();\r\n\r\n    // 3 - have it point at a sound file\r\n    loadSoundFile(filePath);\r\n\r\n    // 4 - create an a source node that points at the <audio> element\r\n    sourceNode = audioCtx.createMediaElementSource(element);\r\n\r\n    // 5 - create an analyser node\r\n    // note the UK spelling of \"Analyser\"\r\n    analyserNode = audioCtx.createAnalyser();\r\n    /*\r\n    // 6\r\n    We will request DEFAULTS.numSamples number of samples or \"bins\" spaced equally \r\n    across the sound spectrum.\r\n    \r\n    If DEFAULTS.numSamples (fftSize) is 256, then the first bin is 0 Hz, the second is 172 Hz, \r\n    the third is 344Hz, and so on. Each bin contains a number between 0-255 representing \r\n    the amplitude of that frequency.\r\n    */\r\n\r\n    // fft stands for Fast Fourier Transform\r\n    analyserNode.fftSize = DEFAULTS.numSamples;\r\n\r\n    // 7 - create a gain (volume) node\r\n    gainNode = audioCtx.createGain();\r\n    gainNode.gain.value = DEFAULTS.gain;\r\n    // 8 - connect the nodes - we now have an audio graph\r\n    \r\n    lowShelfFilter = audioCtx.createBiquadFilter();\r\n    lowShelfFilter.type = \"lowshelf\";\r\n    lowShelfFilter.frequency.value = 500;\r\n    lowShelfFilter.gain.value = 0;\r\n\r\n    highShelfFilter = audioCtx.createBiquadFilter();\r\n    highShelfFilter.type = \"highshelf\";\r\n    highShelfFilter.frequency.value = 2000;\r\n    highShelfFilter.gain.value = 0;\r\n\r\n    sourceNode.connect(lowShelfFilter);\r\n    lowShelfFilter.connect(highShelfFilter);\r\n    highShelfFilter.connect(analyserNode);\r\n    analyserNode.connect(gainNode);\r\n    gainNode.connect(audioCtx.destination);\r\n  \r\n}\r\n\r\nconst loadSoundFile = (filepath) =>{\r\n    element.src = filepath;\r\n}\r\n//play sound\r\nconst playCurrentSound = () =>{\r\n    element.play();\r\n}\r\n//pause sound\r\nconst pauseCurrentSound = () =>{\r\n    element.pause();\r\n}\r\n//set volume\r\nconst setVolume = (value) =>{\r\n    value = Number(value); \r\n    gainNode.gain.value = value;\r\n}\r\n//bass boost\r\nconst bassBoost = (isOn) => {\r\n    if (!lowShelfFilter) return;\r\n    if (isOn) {\r\n        lowShelfFilter.gain.value = 15;\r\n    }\r\n    else {\r\n        lowShelfFilter.gain.value = 0;\r\n    }\r\n    console.log(\"Bass boost:\", lowShelfFilter.gain.value);\r\n}\r\n//treble boost \r\nconst trebleBoost = (isOn) => {\r\n    if (!highShelfFilter) return;\r\n    if (isOn) {\r\n        highShelfFilter.gain.value = 15;\r\n    }\r\n    else {\r\n        highShelfFilter.gain.value = 0;\r\n    }\r\n    console.log(\"Treble boost:\", highShelfFilter.gain.value);\r\n}\r\n\r\n//helper functins\r\nconst createHighShelfFilter = (audioCtx) => {\r\n    let highShelfFilter = audioCtx.createBiquadFilter();\r\n    highShelfFilter.type = \"highshelf\";\r\n    highShelfFilter.frequency.value = 2000;\r\n    highShelfFilter.gain.value = 0;\r\n    sourceNode.disconnect();\r\n    sourceNode.connect(highShelfFilter);\r\n    highShelfFilter.connect(analyserNode);\r\n    return highShelfFilter;\r\n}\r\nconst createLowShelfFilter = (audioCtx) => {\r\n    let lowShelfFilter = audioCtx.createBiquadFilter();\r\n    lowShelfFilter.type = \"lowshelf\";\r\n    lowShelfFilter.frequency.value = 500;\r\n    lowShelfFilter.gain.value = 0;\r\n    analyserNode.disconnect();\r\n    analyserNode.connect(lowShelfFilter);\r\n    lowShelfFilter.connect(gainNode);\r\n    return lowShelfFilter;\r\n}\r\n\r\n\r\n\n\n//# sourceURL=webpack://fishbane-k-hw2/./src/audio.js?\n}");

/***/ }),

/***/ "./src/canvas.js":
/*!***********************!*\
  !*** ./src/canvas.js ***!
  \***********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   draw: () => (/* binding */ draw),\n/* harmony export */   setupCanvas: () => (/* binding */ setupCanvas)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./utils.js */ \"./src/utils.js\");\n/*\r\n    The purpose of this file is to take in the analyser node and a <canvas> element: \r\n      - the module will create a drawing context that points at the <canvas> \r\n      - it will store the reference to the analyser node\r\n      - in draw(), it will loop through the data in the analyser node\r\n      - and then draw something representative on the canvas\r\n      - maybe a better name for this file/module would be *visualizer.js* ?\r\n*/\r\n\r\n\r\n\r\nlet ctx, canvasWidth, canvasHeight, gradient, analyserNode, audioData;\r\nlet sprites = [];\r\n\r\n//Sprite class that draws circles that change size with the music and later in the code changes color based on average energy\r\nclass CircleSprite {\r\n    static type = \"arc\";\r\n    constructor(x, y, radius, color) {\r\n        console.log(`${this.constructor.type} created`);\r\n        this.x = x;\r\n        this.y = y;\r\n        this.radius = radius;\r\n        this.color = color;\r\n\r\n    }\r\n\r\n    update(audioData) {//grows and shrinks with the music \r\n\r\n        let avg = 0;\r\n        for (let i = 0; i < audioData.length; i++) {\r\n            avg += audioData[i] / 20;\r\n        }\r\n        avg /= audioData.length;\r\n        this.radius = avg;\r\n\r\n\r\n\r\n\r\n\r\n    }\r\n\r\n    draw(ctx) {\r\n        ctx.save();\r\n        ctx.fillStyle = this.color;\r\n        ctx.beginPath();\r\n        ctx.arc(this.x, this.y, this.radius, 0, 2 * Math.PI, false);\r\n        ctx.fill();\r\n        ctx.closePath();\r\n        ctx.restore();\r\n    }\r\n}\r\n\r\nconst setupCanvas = (canvasElement, analyserNodeRef) => {\r\n    //creeate drawing context\r\n    ctx = canvasElement.getContext(\"2d\");\r\n\r\n\r\n\r\n    canvasWidth = canvasElement.width;\r\n    canvasHeight = canvasElement.height;\r\n    // create a gradient that runs top to bottom\r\n    gradient = _utils_js__WEBPACK_IMPORTED_MODULE_0__.getLinearGradient(ctx, 0, 0, 0, canvasHeight,\r\n        [{ percent: 0.0, color: \"midnightblue\" },\r\n        { percent: 0.3, color: \"lightseagreen\" },\r\n        { percent: 0.6, color: \"orangered\" },\r\n        { percent: 0.8, color: \"orange\" },\r\n        { percent: 1.0, color: \"gold\" }\r\n        ]);\r\n    analyserNode = analyserNodeRef;\r\n    audioData = new Uint8Array(analyserNode.fftSize / 2);\r\n        //some sprtes to start with\r\n    for (let i = 0; i < 30; i++) {\r\n        let x = Math.random() * canvasWidth;\r\n        let y = Math.random() * canvasHeight;\r\n        let radius = 1;\r\n        let color = _utils_js__WEBPACK_IMPORTED_MODULE_0__.getRandomColor();\r\n\r\n        sprites.push(new CircleSprite(x, y, radius, color));\r\n    }\r\n\r\n}\r\n\r\nconst draw = (params = {}) => {\r\n    // 1 - populate the audioData array with the frequency data from the analyserNode\r\n    // notice these arrays are passed \"by reference\" \r\n    analyserNode.getByteFrequencyData(audioData);\r\n    // OR\r\n    //analyserNode.getByteTimeDomainData(audioData); // waveform data\r\n\r\n    // 2 - draw background\r\n    ctx.save();\r\n    ctx.fillStyle = \"black\";\r\n    ctx.globalAlpha = 0.1;\r\n    ctx.fillRect(0, 0, canvasWidth, canvasHeight);\r\n    ctx.restore();\r\n\r\n    // 3 - draw gradient\r\n    if (params.showGradient) {\r\n        ctx.save();\r\n        ctx.fillStyle = gradient;\r\n        ctx.globalAlpha = 0.3;\r\n        ctx.fillRect(0, 0, canvasWidth, canvasHeight);\r\n        ctx.restore();\r\n    }\r\n\r\n    // 4 - draw bars\r\n    if (params.showBars) {\r\n        let barSpacing = 4;\r\n        let margin = 5;\r\n        let screenWidthForBars = canvasWidth - (audioData.length * barSpacing) - margin * 2;\r\n        let barWidth = screenWidthForBars / audioData.length;\r\n        let barHeight = 200;\r\n        let topSpacing = 100;\r\n\r\n        ctx.save();\r\n        ctx.fillStyle = 'rgba(255,255,255,0.5)';\r\n        ctx.strokeStyle = 'rgba(0,0,0,0.5)';\r\n        //loop through the data and draw\r\n        for (let i = 0; i < audioData.length; i++) {\r\n            ctx.fillRect(margin + i * (barWidth + barSpacing), topSpacing + 256 - audioData[i], barWidth, barHeight);\r\n            ctx.strokeRect(margin + i * (barWidth + barSpacing), topSpacing + 256 - audioData[i], barWidth, barHeight);\r\n        }\r\n        ctx.restore();\r\n    }\r\n\r\n    // 5 - draw circles\r\n    if (params.showCircles) {\r\n        let maxRadius = canvasHeight / 4;\r\n        ctx.save();\r\n        ctx.globalAlpha = 0.5;\r\n        for (let i = 0; i < audioData.length; i++) {\r\n            //red-ish circles\r\n            ctx.save();\r\n            let percent = audioData[i] / 256;\r\n            let circleRadius = percent * maxRadius;\r\n            ctx.beginPath();\r\n            ctx.fillStyle = _utils_js__WEBPACK_IMPORTED_MODULE_0__.makeColor(255, 111, 111, .34 - percent / 3.0);\r\n            ctx.arc(canvasWidth / 2, canvasHeight / 2, circleRadius, 0, 2 * Math.PI, false);\r\n            ctx.fill();\r\n            ctx.closePath();\r\n            ctx.restore();\r\n\r\n            ctx.save();\r\n            //blue-ish circles bigger and more transparent\r\n            ctx.beginPath();\r\n            ctx.fillStyle = _utils_js__WEBPACK_IMPORTED_MODULE_0__.makeColor(0, 0, 255, 0.10 - percent / 10.0);\r\n            ctx.arc(canvasWidth / 2, canvasHeight / 2, circleRadius * 1.5, 0, 2 * Math.PI, false);\r\n            ctx.fill();\r\n            ctx.closePath();\r\n            ctx.restore();\r\n\r\n            //yellow-ish circles smaller\r\n            ctx.save();\r\n            ctx.beginPath();\r\n            ctx.fillStyle = _utils_js__WEBPACK_IMPORTED_MODULE_0__.makeColor(200, 200, 0, 0.5 - percent / 5.0);\r\n            ctx.arc(canvasWidth / 2, canvasHeight / 2, circleRadius * 0.5, 0, 2 * Math.PI, false);\r\n            ctx.fill();\r\n            ctx.closePath();\r\n            ctx.restore();\r\n        }\r\n        ctx.restore();\r\n    }\r\n    // 6 - bitmap manipulation\r\n    // TODO: right now. we are looping though every pixel of the canvas (320,000 of them!), \r\n    // regardless of whether or not we are applying a pixel effect\r\n    // At some point, refactor this code so that we are looping though the image data only if\r\n    // it is necessary\r\n\r\n    // A) grab all of the pixels on the canvas and put them in the `data` array\r\n    // `imageData.data` is a `Uint8ClampedArray()` typed array that has 1.28 million elements!\r\n    // the variable `data` below is a reference to that array \r\n    let imageData = ctx.getImageData(0, 0, canvasWidth, canvasHeight);\r\n    let data = imageData.data;\r\n    let length = data.length;\r\n    let width = imageData.width;//not used here\r\n    if (params.showEmboss) {\r\n        for (let i = 0; i < length; i++) {\r\n            if (i % 4 == 3) continue;\r\n            data[i] = 127 + 2 * data[i] - data[i + 4] - data[i + width * 4];\r\n        }\r\n    }\r\n\r\n    // B) Iterate through each pixel, stepping 4 elements at a time (which is the RGBA for 1 pixel)\r\n    for (let i = 0; i < length; i += 4) {\r\n        // C) randomly change every 20th pixel to red\r\n        if (params.showNoise && Math.random() < 0.05) {\r\n            // data[i] is the red channel\r\n            // data[i+1] is the green channel\r\n            // data[i+2] is the blue channel\r\n            // data[i+3] is the alpha channel\r\n            data[i] = data[i + 1] = data[i + 2] = 0; // zero out the red and green and blue channels\r\n            //make the noise best color orange\r\n            data[i] = 200;\r\n            data[i + 1] = 150;\r\n            data[i + 2] = 50;\r\n\r\n\r\n        } // end if\r\n        if (params.showInvert) {\r\n            let red = data[i], green = data[i + 1], blue = data[i + 2];\r\n            data[i] = 255 - red;\r\n            data[i + 1] = 255 - green;\r\n            data[i + 2] = 255 - blue;\r\n        }\r\n    } // end for\r\n    // D) copy image data back to canvas\r\n    ctx.putImageData(imageData, 0, 0);\r\n\r\n    //Give the user the ability to toggle between the visualization using the \"frequency data\" and the \"time domain\" (i.e. waveform) data.\r\n    if (params.showWaveform) {\r\n        analyserNode.getByteTimeDomainData(audioData); // waveform data\r\n        ctx.save();\r\n        ctx.lineWidth = 10;\r\n        ctx.strokeStyle = 'rgba(209, 32, 32, 0.5)';\r\n        ctx.beginPath();\r\n        let sliceWidth = canvasWidth * 1.0 / audioData.length;\r\n        let x = 0;\r\n        for (let i = 0; i < audioData.length; i++) {\r\n            let v = audioData[i] / 128.0;\r\n            let y = v * canvasHeight / 2;\r\n            if (i === 0) {\r\n                ctx.moveTo(x, y);\r\n            } else {\r\n                ctx.lineTo(x, y);\r\n            }\r\n            x += sliceWidth;\r\n        }\r\n        ctx.stroke();\r\n        ctx.closePath();\r\n        ctx.restore();\r\n    }\r\n\r\n    for (let sprite of sprites) {\r\n        sprite.update(audioData);\r\n        sprite.draw(ctx);\r\n    }\r\n\r\n\r\n    //calculate average energy\r\n    let avgEnergy = 0;\r\n    for (let i = 0; i < audioData.length; i++) {\r\n        avgEnergy += audioData[i];\r\n    }\r\n    avgEnergy /= audioData.length;\r\n\r\n    //compare average energy to previous average energy\r\n    if (!draw.prevEnergy) {\r\n        draw.prevEnergy = avgEnergy;\r\n    }\r\n    let energyDiff = avgEnergy - draw.prevEnergy;\r\n    draw.prevEnergy = avgEnergy;\r\n\r\n    //if average energy has increased significantly, add more sprites\r\n    if (energyDiff > 15 && sprites.length < 60) {\r\n        for (let i = 0; i < 3; i++) {\r\n            sprites.push(\r\n                new CircleSprite(Math.random() * canvasWidth, Math.random() * canvasHeight,\r\n                    1 + Math.random() * 3,\r\n                    _utils_js__WEBPACK_IMPORTED_MODULE_0__.getRandomColor()\r\n                )\r\n            );\r\n        }\r\n    }\r\n\r\n    //change color of sprites based on average energy\r\n    for (let sprite of sprites) {\r\n        //if low energy aliceblue with some random color\r\n        if (avgEnergy < 50) {\r\n            if(Math.random() < 0.05) {\r\n                sprite.color = _utils_js__WEBPACK_IMPORTED_MODULE_0__.getRandomColor();\r\n            }\r\n            else{\r\n                sprite.color = \"AliceBlue\";\r\n            }\r\n            //if medium energy more random colors\r\n        } else if (avgEnergy < 130) {\r\n           if(Math.random() < 0.4) {\r\n                sprite.color = _utils_js__WEBPACK_IMPORTED_MODULE_0__.getRandomColor();\r\n            }\r\n            else{\r\n                sprite.color = \"AliceBlue\";\r\n            }\r\n            //if high energy always choose a random color\r\n        } else {\r\n            \r\n            sprite.color = _utils_js__WEBPACK_IMPORTED_MODULE_0__.getRandomColor();\r\n        }\r\n    }\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n}\r\n\r\n\n\n//# sourceURL=webpack://fishbane-k-hw2/./src/canvas.js?\n}");

/***/ }),

/***/ "./src/main.js":
/*!*********************!*\
  !*** ./src/main.js ***!
  \*********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   init: () => (/* binding */ init)\n/* harmony export */ });\n/* harmony import */ var _audio_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./audio.js */ \"./src/audio.js\");\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./utils.js */ \"./src/utils.js\");\n/* harmony import */ var _canvas_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./canvas.js */ \"./src/canvas.js\");\n/*\r\n  main.js is primarily responsible for hooking up the UI to the rest of the application \r\n  and setting up the main event loop\r\n*/\r\n\r\n// We will write the functions in this file in the traditional ES5 way\r\n// In this instance, we feel the code is more readable if written this way\r\n// If you want to re-write these as ES6 arrow functions, to be consistent with the other files, go ahead!\r\n\r\n\r\n\r\nlet drawParams = {\r\n};\r\n\r\n\r\n// 1 - here we are faking an enumeration\r\nconst DEFAULTS = Object.freeze({\r\n  sound1: \"media/New Adventure Theme.mp3\"\r\n});\r\n\r\nconst init = () => {\r\n\r\n  console.log(\"init called\");\r\n  console.log(`Testing utils.getRandomColor() import: ${_utils_js__WEBPACK_IMPORTED_MODULE_1__.getRandomColor()}`);\r\n  _audio_js__WEBPACK_IMPORTED_MODULE_0__.setupWebaudio(DEFAULTS.sound1);\r\n  let canvasElement = document.querySelector(\"canvas\");\r\n  setupUI(canvasElement);\r\n  _canvas_js__WEBPACK_IMPORTED_MODULE_2__.setupCanvas(canvasElement, _audio_js__WEBPACK_IMPORTED_MODULE_0__.analyserNode);\r\n  fetchDefaultState();\r\n  fetchSongs();\r\n  fetchAppTitle();\r\n\r\n  loop();\r\n}\r\n\r\nconst setupUI = (canvasElement) => {\r\n  // A - hookup fullscreen button\r\n  const fsButton = document.querySelector(\"#fs-button\");\r\n  const playButton = document.querySelector(\"#play-button\");\r\n\r\n  // add .onclick event to button\r\n  fsButton.onclick = e => {\r\n    console.log(\"goFullscreen() called\");\r\n    _utils_js__WEBPACK_IMPORTED_MODULE_1__.goFullscreen(canvasElement);\r\n  };\r\n  playButton.onclick = e => {\r\n    console.log(`audio.audioCtx state = ${_audio_js__WEBPACK_IMPORTED_MODULE_0__.audioCtx.state}`);\r\n\r\n    if (_audio_js__WEBPACK_IMPORTED_MODULE_0__.audioCtx.state == 'suspended') {\r\n      _audio_js__WEBPACK_IMPORTED_MODULE_0__.audioCtx.resume();\r\n    }\r\n    console.log(`audioCtx state = ${_audio_js__WEBPACK_IMPORTED_MODULE_0__.audioCtx.state}`);\r\n    if (e.target.dataset.playing == \"no\") {\r\n      _audio_js__WEBPACK_IMPORTED_MODULE_0__.playCurrentSound();\r\n      e.target.dataset.playing = \"yes\";\r\n    } else {\r\n      _audio_js__WEBPACK_IMPORTED_MODULE_0__.pauseCurrentSound();\r\n      e.target.dataset.playing = \"no\";\r\n    }\r\n  };\r\n  // C - hookup volume slider and label\r\n  const volumeSlider = document.querySelector(\"#volume-slider\");\r\n  const volumeLabel = document.querySelector(\"#volume-label\");\r\n  //add .oninput event to slider\r\n  volumeSlider.oninput = e => {\r\n    //set the gain\r\n    _audio_js__WEBPACK_IMPORTED_MODULE_0__.setVolume(e.target.value);\r\n    //update the value of the label to match value of slider\r\n    volumeLabel.innerHTML = Math.round((e.target.value / 2 * 100));\r\n  };\r\n  //set value of label to match initial value of slider\r\n  volumeSlider.dispatchEvent(new Event(\"input\"));\r\n\r\n  //D - hookup track <select>\r\n  let trackSelect = document.querySelector(\"#track-select\");\r\n  //add .onchange event to <select>\r\n  trackSelect.onchange = e => {\r\n    _audio_js__WEBPACK_IMPORTED_MODULE_0__.loadSoundFile(e.target.value);\r\n    //pause the current track if it is playing\r\n    if (playButton.dataset.playing == \"yes\") {\r\n      playButton.dispatchEvent(new MouseEvent(\"click\"));\r\n    }\r\n  };\r\n\r\n  //E - hookup checkboxes\r\n  let gradientCB = document.querySelector(\"#gradient-CB\");\r\n  let barsCB = document.querySelector(\"#bars-CB\");\r\n  let circlesCB = document.querySelector(\"#circles-CB\");\r\n  let noiseCB = document.querySelector(\"#noise-CB\");\r\n  let invertCB = document.querySelector(\"#invert-CB\");\r\n  let embossCB = document.querySelector(\"#emboss-CB\");\r\n  let waveformCB = document.querySelector(\"#waveform-CB\");\r\n  let bassCB = document.querySelector(\"#bass-CB\");\r\n  let trebleCB = document.querySelector(\"#treble-CB\");\r\n\r\n  waveformCB.onchange = e => {\r\n    drawParams.showWaveform = e.target.checked;\r\n  }\r\n  bassCB.onchange = e => {\r\n    drawParams.showBass = e.target.checked;\r\n    _audio_js__WEBPACK_IMPORTED_MODULE_0__.bassBoost(e.target.checked);\r\n  }\r\n\r\n  trebleCB.onchange = e => {\r\n    drawParams.showTreble = e.target.checked;\r\n    _audio_js__WEBPACK_IMPORTED_MODULE_0__.trebleBoost(e.target.checked);\r\n  }\r\n\r\n\r\n\r\n  gradientCB.onchange = e => {\r\n    drawParams.showGradient = e.target.checked;\r\n  }\r\n  barsCB.onchange = e => {\r\n    drawParams.showBars = e.target.checked;\r\n  }\r\n  circlesCB.onchange = e => {\r\n    drawParams.showCircles = e.target.checked;\r\n  }\r\n  noiseCB.onchange = e => {\r\n    drawParams.showNoise = e.target.checked;\r\n\r\n  }\r\n  invertCB.onchange = e => {\r\n    drawParams.showInvert = e.target.checked;\r\n  }\r\n  embossCB.onchange = e => {\r\n    drawParams.showEmboss = e.target.checked;\r\n  }\r\n\r\n\r\n\r\n\r\n} // end setupUI\r\n\r\nconst loop = () => {\r\n\r\n  setTimeout(loop, 1000 / 60); //60 fps\r\n  _canvas_js__WEBPACK_IMPORTED_MODULE_2__.draw(drawParams);\r\n\r\n}\r\n//fetch songs from json file\r\nconst fetchSongs = () => {\r\n  const url = \"data/av-data.json\";\r\n  const category = \"songs\";\r\n  const trackSelect = document.querySelector(\"#track-select\");\r\n  const callback = (data) => {\r\n    console.log(\"fetchSongs callback called\");\r\n    console.log(data);\r\n    for (let song of data) {\r\n      let option = document.createElement(\"option\");\r\n      option.value = song.url;\r\n      option.innerHTML = song.title;\r\n      trackSelect.appendChild(option);\r\n    }\r\n  };\r\n  _utils_js__WEBPACK_IMPORTED_MODULE_1__.fetchData(url, category, callback);\r\n\r\n\r\n}\r\n//fetch default state from json file\r\nconst fetchDefaultState = () => {\r\n  const url = \"data/av-data.json\";\r\n  const category = \"defaults\";\r\n  const callback = (data) => {\r\n    console.log(\"fetchDefaultState callback called\");\r\n    console.log(data);\r\n    let def = data[0];\r\n    //set drawParams default state\r\n    drawParams.showGradient = def.gradient;\r\n    drawParams.showBars = def.bars;\r\n    drawParams.showCircles = def.circles;\r\n    drawParams.showNoise = def.noise;\r\n    drawParams.showInvert = def.invert;\r\n    drawParams.showEmboss = def.emboss;\r\n    drawParams.showWaveform = def.waveform;\r\n    drawParams.showBass = def.bass;\r\n    drawParams.showTreble = def.treble;\r\n    console.log(drawParams);\r\n    //set the checkboxes to match the default state\r\n    document.querySelector(\"#gradient-CB\").checked = drawParams.showGradient;\r\n    document.querySelector(\"#bars-CB\").checked = drawParams.showBars;\r\n    document.querySelector(\"#circles-CB\").checked = drawParams.showCircles;\r\n    document.querySelector(\"#noise-CB\").checked = drawParams.showNoise;\r\n    document.querySelector(\"#invert-CB\").checked = drawParams.showInvert;\r\n    document.querySelector(\"#emboss-CB\").checked = drawParams.showEmboss;\r\n    document.querySelector(\"#waveform-CB\").checked = drawParams.showWaveform;\r\n    document.querySelector(\"#bass-CB\").checked = drawParams.showBass;\r\n    document.querySelector(\"#treble-CB\").checked = drawParams.showTreble;\r\n\r\n    _canvas_js__WEBPACK_IMPORTED_MODULE_2__.draw(drawParams);\r\n\r\n  };\r\n\r\n\r\n  _utils_js__WEBPACK_IMPORTED_MODULE_1__.fetchData(url, category, callback);\r\n}\r\n\r\n//fetch app title from json file\r\nconst fetchAppTitle = () => {\r\n  const url = \"data/av-data.json\";\r\n  const category = \"title\";\r\n\r\n  const callback = (data) => {\r\n    document.title = data;\r\n    const h1 = document.querySelector(\"h1\");\r\n    if (h1) h1.textContent = data;\r\n  };\r\n\r\n  _utils_js__WEBPACK_IMPORTED_MODULE_1__.fetchData(url, category, callback);\r\n};\r\n\r\n\r\n\r\n\r\n\n\n//# sourceURL=webpack://fishbane-k-hw2/./src/main.js?\n}");

/***/ }),

/***/ "./src/utils.js":
/*!**********************!*\
  !*** ./src/utils.js ***!
  \**********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   fetchData: () => (/* binding */ fetchData),\n/* harmony export */   getLinearGradient: () => (/* binding */ getLinearGradient),\n/* harmony export */   getRandomColor: () => (/* binding */ getRandomColor),\n/* harmony export */   goFullscreen: () => (/* binding */ goFullscreen),\n/* harmony export */   makeColor: () => (/* binding */ makeColor)\n/* harmony export */ });\nconst makeColor = (red, green, blue, alpha = 1) => {\r\n  return `rgba(${red},${green},${blue},${alpha})`;\r\n};\r\n\r\nconst getRandom = (min, max) => {\r\n  return Math.random() * (max - min) + min;\r\n};\r\n\r\nconst getRandomColor = () => {\r\n  const floor = 35; // so that colors are not too bright or too dark \r\n  const getByte = () => getRandom(floor,255-floor);\r\n  return `rgba(${getByte()},${getByte()},${getByte()},1)`;\r\n};\r\n\r\nconst getLinearGradient = (ctx,startX,startY,endX,endY,colorStops) => {\r\n  let lg = ctx.createLinearGradient(startX,startY,endX,endY);\r\n  for(let stop of colorStops){\r\n    lg.addColorStop(stop.percent,stop.color);\r\n  }\r\n  return lg;\r\n};\r\n\r\n// https://developer.mozilla.org/en-US/docs/Web/API/Fullscreen_API\r\nconst goFullscreen = (element) => {\r\n  if (element.requestFullscreen) {\r\n    element.requestFullscreen();\r\n  } else if (element.mozRequestFullscreen) {\r\n    element.mozRequestFullscreen();\r\n  } else if (element.mozRequestFullScreen) { // camel-cased 'S' was changed to 's' in spec\r\n    element.mozRequestFullScreen();\r\n  } else if (element.webkitRequestFullscreen) {\r\n    element.webkitRequestFullscreen();\r\n  }\r\n  // .. and do nothing if the method is not supported\r\n};\r\nconst fetchData = (url, category, callback) => {\r\n  const xhr = new XMLHttpRequest();\r\n  xhr.open('GET', url, true);\r\n  xhr.onload = (e) => {\r\n      if (xhr.status === 200) { \r\n          try {\r\n              \r\n              let responseData = e.target.responseText;\r\n              responseData = JSON.parse(responseData);\r\n              const data = responseData[category] || []; \r\n              callback(data); \r\n          } catch (error) {\r\n              console.error('Error parsing JSON:', error);\r\n          }\r\n      } else {\r\n          console.error('Failed to load data');\r\n      }\r\n  };\r\n  xhr.onerror = () => console.error('XHR request error');\r\n  xhr.send();\r\n};\r\n\r\n\r\n        \r\n\r\n\n\n//# sourceURL=webpack://fishbane-k-hw2/./src/utils.js?\n}");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			// no module.id needed
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId](module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/define property getters */
/******/ 	(() => {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = (exports, definition) => {
/******/ 			for(var key in definition) {
/******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 				}
/******/ 			}
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	(() => {
/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	})();
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module can't be inlined because the eval devtool is used.
/******/ 	var __webpack_exports__ = __webpack_require__("./src/main.js");
/******/ 	
/******/ })()
;